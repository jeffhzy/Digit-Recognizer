{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Digit Recognizer","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents  \n\n1. [Introduction](#section-1)\n2. [Exploratory Data Analysis](#section-2)\n3. [Data Preprocessing](#section-3)\n4. [Machine Learning Models](#section-4)  \n    4.1. [Neural Network with Densely Connected Layers](#section-4.1)  \n    4.2. [Convolutional Neural Network](#section-4.2)  \n5. [Final Comments](#section-5)","metadata":{}},{"cell_type":"markdown","source":"---\n## Introduction <a id=\"section-1\"></a>","metadata":{}},{"cell_type":"markdown","source":"This project aims to classify an image containing a handwritten digit into 1 of 10 categories, ranging from 0 to 9. To do so, I will be applying two neural networks, with the networks differing in terms of the type of layers used:\n\n * A network containing only **densely connected** layers\n * A network containing a mix of **convolutional and densely connected** layers\n \nI will then evaluate the performace of the two models using the test set to compare which model gives the higher accuracy. To begin, I will first proceed with an overview of the dataset.","metadata":{}},{"cell_type":"markdown","source":"---\n## Exploratory Data Analysis <a id=\"section-2\"></a>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# storing the test and training data into variables\ntrain_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:36.953569Z","iopub.execute_input":"2023-05-22T22:01:36.954066Z","iopub.status.idle":"2023-05-22T22:01:41.009084Z","shell.execute_reply.started":"2023-05-22T22:01:36.954030Z","shell.execute_reply":"2023-05-22T22:01:41.007302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:41.010934Z","iopub.execute_input":"2023-05-22T22:01:41.011609Z","iopub.status.idle":"2023-05-22T22:01:41.019143Z","shell.execute_reply.started":"2023-05-22T22:01:41.011560Z","shell.execute_reply":"2023-05-22T22:01:41.017758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training data contains 42000 observations (images in this case) and 785 attributes for each observation. The attributes and their meanings are as listed below:  \n\n**label**: Ground truth of the handwritten digit, classified into 10 classes (0 to 9)  \n**pixeln**: The nth pixel of the image, containing values which signify the level of greyness of each pixel\n\nEach image is of the dimension (28 * 28 * 1), which represent the **image height**, **image width** and **image channels** respectively.","metadata":{}},{"cell_type":"code","source":"# plotting the distribution of the labels\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(x = train_data['label'])\nplt.title(\"Distribution of labels\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:41.020844Z","iopub.execute_input":"2023-05-22T22:01:41.021437Z","iopub.status.idle":"2023-05-22T22:01:42.243550Z","shell.execute_reply.started":"2023-05-22T22:01:41.021394Z","shell.execute_reply":"2023-05-22T22:01:42.242040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a count table for labels\nprint(\"=== Label ===\")\nlabel_count = train_data['label'].value_counts().sort_values().reset_index()\nlabel_count.columns = [\"label\", \"counts\"]\nlabel_count = label_count.sort_values(by=\"label\")\nprint(label_count.to_string(index=False))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:42.246630Z","iopub.execute_input":"2023-05-22T22:01:42.247225Z","iopub.status.idle":"2023-05-22T22:01:42.261479Z","shell.execute_reply.started":"2023-05-22T22:01:42.247193Z","shell.execute_reply":"2023-05-22T22:01:42.260147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The labels of the training set seem to be almost equally distributed, with the label 5 appearing the least (3795 times) and label 1 appearing the most (4684 times).","metadata":{}},{"cell_type":"code","source":"# visualizing the dataset\ntrain_data_reshaped = train_data.drop(['label'], axis=1).values.reshape(-1, 28, 28)\nplt.figure(figsize=(10, 15))\nfor i in range(10):\n    plt.subplot(5, 5, i+1)\n    plt.grid(False)\n    plt.imshow(train_data_reshaped[i])\n    plt.xlabel(train_data['label'].iloc[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:42.262866Z","iopub.execute_input":"2023-05-22T22:01:42.263189Z","iopub.status.idle":"2023-05-22T22:01:43.141617Z","shell.execute_reply.started":"2023-05-22T22:01:42.263161Z","shell.execute_reply":"2023-05-22T22:01:43.140274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first 10 images and their respective labels are plotted above.","metadata":{}},{"cell_type":"code","source":"# getting the range for channels dimension\nmax_channel = max(train_data.max())\nmin_channel = min(train_data.min())\nprint(f\"Minimum channel: {min_channel}\")\nprint(f\"Maximum channel: {max_channel}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:43.143255Z","iopub.execute_input":"2023-05-22T22:01:43.143599Z","iopub.status.idle":"2023-05-22T22:01:43.183510Z","shell.execute_reply.started":"2023-05-22T22:01:43.143572Z","shell.execute_reply":"2023-05-22T22:01:43.182180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The coefficient for the pixel attribute ranges from 0 to 255, which represent the intensity of the greyscale. I shall now proceed with processing the data.","metadata":{}},{"cell_type":"markdown","source":"---\n## Data Preprocessing <a id=\"section-3\"></a>","metadata":{}},{"cell_type":"code","source":"# extracting labels from training data\ntrain_labels = train_data['label']\ntrain_data.drop(['label'], axis=1, inplace= True)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:43.184909Z","iopub.execute_input":"2023-05-22T22:01:43.185310Z","iopub.status.idle":"2023-05-22T22:01:43.243337Z","shell.execute_reply.started":"2023-05-22T22:01:43.185275Z","shell.execute_reply":"2023-05-22T22:01:43.242429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize the coefficient of pixels\ndef normalize_coef(data):\n    return data.astype(\"float32\")/ 255\n\ntrain_data = normalize_coef(train_data)\ntest_data = normalize_coef(test_data)\nnormalized_max_channel = max(train_data.max())\nnormalized_min_channel = min(train_data.min())\nprint(f\"Normalized minimum channel: {normalized_min_channel}\")\nprint(f\"Normalized maximum channel: {normalized_max_channel}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:43.244561Z","iopub.execute_input":"2023-05-22T22:01:43.246137Z","iopub.status.idle":"2023-05-22T22:01:43.455222Z","shell.execute_reply.started":"2023-05-22T22:01:43.246108Z","shell.execute_reply":"2023-05-22T22:01:43.453539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I normalized the coefficient of all pixel attributes for both training and test set such that the range of values they can take lie between 0 and 1. This creates a homogeneous dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# splitting the dataset into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, train_size = 0.80, random_state = 42)\nprint(f\"Number of samples in training set: {X_train.shape[0]}\")\nprint(f\"Number of samples in validation set: {X_val.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:43.456711Z","iopub.execute_input":"2023-05-22T22:01:43.457045Z","iopub.status.idle":"2023-05-22T22:01:44.031082Z","shell.execute_reply.started":"2023-05-22T22:01:43.457016Z","shell.execute_reply":"2023-05-22T22:01:44.030160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I split the training data into training and validation sets in a 80/20 split. The validation set will help us in finetuning the hyperparameters of the model later on.","metadata":{}},{"cell_type":"code","source":"from keras.utils import to_categorical\n\ny_train = to_categorical(y_train)\ny_val = to_categorical(y_val)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:44.034140Z","iopub.execute_input":"2023-05-22T22:01:44.035231Z","iopub.status.idle":"2023-05-22T22:01:51.652888Z","shell.execute_reply.started":"2023-05-22T22:01:44.035192Z","shell.execute_reply":"2023-05-22T22:01:51.651300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the labels can only fall into 10 categories, I applied one hot encoding to the labels for easier processing in the neural network.","metadata":{}},{"cell_type":"markdown","source":"---\n## Machine Learning Models <a id=\"section-4\"></a>","metadata":{}},{"cell_type":"markdown","source":"### Neural Network with Densely Connected Layers<a id=\"section-4.1\"></a>","metadata":{}},{"cell_type":"markdown","source":"For this portion, I will be trying out 3 neural networks with different hyperparameters, namely:  \n   1. Neural Network with 1 hidden layer and 256 hidden inputs  \n   2. Neural Network with 1 hidden layer and 512 hidden inputs  \n   3. Neural Network with 2 hidden layers and 512 hidden inputs per hidden layer  \n\nEach network will be run for a total of 20 epochs using a batch size of 128. I will use the relu activation function for the hidden layers to account for the possibility of non-linear relationships, and the softmax activation function for the output layer to generate a probability distribution over the 10 different labels. Dropouts are applied to each hidden layer to reduce overfitting. Lastly, I will evaluate the performance of each network against the validation set using the accuracy metric.","metadata":{}},{"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\n# creating a function that outputs a new model using the given parameters\ndef build_model(num_hidden_inputs, num_hidden_layers):\n    model = models.Sequential()\n    for i in range(num_hidden_layers):\n        if i == 0:\n            model.add(layers.Dense(num_hidden_inputs, activation=\"relu\", input_shape=(784,)))\n        else:\n            model.add(layers.Dense(num_hidden_inputs, activation=\"relu\"))\n        model.add(layers.Dropout(0.3))\n    model.add(layers.Dense(10, activation=\"softmax\"))\n    model.compile(optimizer=\"rmsprop\",\n                 loss=\"categorical_crossentropy\",\n                 metrics=[\"accuracy\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:51.654482Z","iopub.execute_input":"2023-05-22T22:01:51.655394Z","iopub.status.idle":"2023-05-22T22:01:51.663418Z","shell.execute_reply.started":"2023-05-22T22:01:51.655361Z","shell.execute_reply":"2023-05-22T22:01:51.662123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# neural network with 1 hidden layer and 256 hidden inputs\nmodel1 = build_model(256, 1).fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val), verbose=0)\n\n# neural network with 1 hidden layer and 512 hidden inputs\nmodel2 = build_model(512, 1).fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val), verbose=0)\n\n# neural network with 2 hidden layers and 512 hidden inputs per hidden layer\nmodel3 = build_model(512, 2).fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val), verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:01:51.665319Z","iopub.execute_input":"2023-05-22T22:01:51.665733Z","iopub.status.idle":"2023-05-22T22:04:16.462651Z","shell.execute_reply.started":"2023-05-22T22:01:51.665703Z","shell.execute_reply":"2023-05-22T22:04:16.461867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extracting the validation accuracy values from each model\nmodel1_val_acc = model1.history['val_accuracy']\nmodel2_val_acc = model2.history['val_accuracy']\nmodel3_val_acc = model3.history['val_accuracy']\n\n# plotting validation accuracies against epoch\nepochs = range(1, 21)\nplt.plot(epochs, model1_val_acc, label=\"Model1 Val Acc\")\nplt.plot(epochs, model2_val_acc, label=\"Model2 Val Acc\")\nplt.plot(epochs, model3_val_acc, label=\"Model3 Val Acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:04:16.466881Z","iopub.execute_input":"2023-05-22T22:04:16.468113Z","iopub.status.idle":"2023-05-22T22:04:16.674128Z","shell.execute_reply.started":"2023-05-22T22:04:16.468075Z","shell.execute_reply":"2023-05-22T22:04:16.672646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the graph, model 3 seems to perform the best as it has the highest validation accuracy across all 3 models. The graph also shows that the performance on the validation set seems to deteriorate after the 17 epoch, likely due to overfitting on the training set. I will now train model 3 using all the available training data (training set + validation set) for a total of 17 epochs, and finally test the accuracy on the test set. ","metadata":{}},{"cell_type":"code","source":"# training the final model\nfinal_nn = build_model(512, 2)\nfinal_nn.fit(train_data, to_categorical(train_labels), epochs=17, batch_size=128) ","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:04:16.675500Z","iopub.execute_input":"2023-05-22T22:04:16.675757Z","iopub.status.idle":"2023-05-22T22:05:30.732225Z","shell.execute_reply.started":"2023-05-22T22:04:16.675736Z","shell.execute_reply":"2023-05-22T22:05:30.731331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the predictions on the test set\nfinal_nn_predictions = final_nn.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:05:30.735577Z","iopub.execute_input":"2023-05-22T22:05:30.735926Z","iopub.status.idle":"2023-05-22T22:05:34.638999Z","shell.execute_reply.started":"2023-05-22T22:05:30.735897Z","shell.execute_reply":"2023-05-22T22:05:34.637537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nfinal_nn_predicted_classes = np.argmax(final_nn_predictions, axis=1)\nImageId = list(range(1, len(final_nn_predicted_classes) + 1))\nsubmissions = pd.DataFrame({\"ImageId\": ImageId,\n                           \"Label\": final_nn_predicted_classes})\nsubmissions.to_csv(\"submission_nn.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:05:34.641242Z","iopub.execute_input":"2023-05-22T22:05:34.641584Z","iopub.status.idle":"2023-05-22T22:05:34.690719Z","shell.execute_reply.started":"2023-05-22T22:05:34.641562Z","shell.execute_reply":"2023-05-22T22:05:34.689283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has a 98.028% accuracy when evaluated against the test set. Now, I will build a CNN and compare its performance against the earlier model.","metadata":{}},{"cell_type":"markdown","source":"### Convolutional Neural Network<a id=\"section-4.2\"></a>","metadata":{}},{"cell_type":"markdown","source":"For the convolutional neural network, I will use 3 convolutional layers, each with 32, 64, 64 filters respectively as well as a densely connected layer with 64 hidden inputs. I also included MaxPooling2D layers to ensure that the model can better learn the spacial hierachy of features. The output of the model will be of the same format as the output from the previous models.","metadata":{}},{"cell_type":"code","source":"# building the CNN\n\ndef build_cnn():\n    cnn_model = models.Sequential()\n    cnn_model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28,28,1)))\n    cnn_model.add(layers.MaxPooling2D((2, 2)))\n    cnn_model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n    cnn_model.add(layers.MaxPooling2D((2, 2)))\n    cnn_model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n    cnn_model.add(layers.Flatten())\n    cnn_model.add(layers.Dense(64, activation=\"relu\"))\n    cnn_model.add(layers.Dense(10, activation=\"softmax\"))\n    cnn_model.compile(optimizer=\"rmsprop\",\n                 loss=\"categorical_crossentropy\",\n                 metrics=[\"accuracy\"])\n    return cnn_model","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:24:12.127330Z","iopub.execute_input":"2023-05-22T22:24:12.127862Z","iopub.status.idle":"2023-05-22T22:24:12.136737Z","shell.execute_reply.started":"2023-05-22T22:24:12.127825Z","shell.execute_reply":"2023-05-22T22:24:12.135155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaping the dataframe into a 4D tensor\nX_train_cnn = X_train.values.reshape((33600, 28, 28, 1))\nX_val_cnn = X_val.values.reshape((8400, 28, 28, 1))\ncnn_model = build_cnn()\ncnn_model.fit(X_train_cnn, y_train, epochs=20, batch_size=64, validation_data=(X_val_cnn, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:24:51.246459Z","iopub.execute_input":"2023-05-22T22:24:51.246854Z","iopub.status.idle":"2023-05-22T22:30:14.085704Z","shell.execute_reply.started":"2023-05-22T22:24:51.246830Z","shell.execute_reply":"2023-05-22T22:30:14.084825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extracting the validation accuracy value the model\ncnn_val_acc = cnn_model.history.history['val_accuracy']\n\n# plotting validation accuracies against epoch\nepochs = range(1, 21)\nplt.plot(epochs, cnn_val_acc, label=\"CNN Val Acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:32:59.055675Z","iopub.execute_input":"2023-05-22T22:32:59.056038Z","iopub.status.idle":"2023-05-22T22:32:59.240398Z","shell.execute_reply.started":"2023-05-22T22:32:59.056015Z","shell.execute_reply":"2023-05-22T22:32:59.238740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model fails to show significant improvements on the validation data after the 10th epoch. I will now train the final CNN model with all available training data.","metadata":{}},{"cell_type":"code","source":"# training the final cnn model on all available training data\ncnn_train_data = train_data.values.reshape((42000, 28, 28, 1))\nfinal_cnn = build_cnn()\nfinal_cnn.fit(cnn_train_data, to_categorical(train_labels), epochs=10, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:34:27.840602Z","iopub.execute_input":"2023-05-22T22:34:27.840987Z","iopub.status.idle":"2023-05-22T22:37:14.304235Z","shell.execute_reply.started":"2023-05-22T22:34:27.840959Z","shell.execute_reply":"2023-05-22T22:37:14.303222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the predictions on the test set\ntest_data_reshaped = test_data.values.reshape((28000, 28, 28, 1))\nfinal_cnn_predictions = final_cnn.predict(test_data_reshaped)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:38:22.897259Z","iopub.execute_input":"2023-05-22T22:38:22.897677Z","iopub.status.idle":"2023-05-22T22:38:28.710855Z","shell.execute_reply.started":"2023-05-22T22:38:22.897645Z","shell.execute_reply":"2023-05-22T22:38:28.709952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_cnn_predicted_classes = np.argmax(final_cnn_predictions, axis=1)\ncnn_submissions = pd.DataFrame({\"ImageId\": ImageId,\n                           \"Label\": final_cnn_predicted_classes})\ncnn_submissions.to_csv(\"submission_cnn.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T22:38:33.849512Z","iopub.execute_input":"2023-05-22T22:38:33.849884Z","iopub.status.idle":"2023-05-22T22:38:33.896926Z","shell.execute_reply.started":"2023-05-22T22:38:33.849856Z","shell.execute_reply":"2023-05-22T22:38:33.895212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has a 99.017% accuracy when evaluated against the test set.","metadata":{}},{"cell_type":"markdown","source":"---\n## Final Comments <a id=\"section-5\"></a>","metadata":{}},{"cell_type":"markdown","source":"Overall, the CNN has a slightly higher accuracy than the NN with only dense layers, albeit coming at the cost of computational time. To further improve accuracy, I can perhaps further finetune the hyperparameters of the model, and use k-folds validation to ensure that the validation set is representative of the overall data set.","metadata":{}}]}